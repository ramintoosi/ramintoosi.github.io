---
layout: archive
title: "Education"
permalink: /education/
author_profile: true
---

<style>
    table {
        width: 100%;
        font-size: 20px;
        font-weight: bold;
        background-color: $light-gray;
    }

    table tbody tr td:nth-child(1){width:25%;}
    table tbody tr td:nth-child(2){width:50%;}
    table tbody tr td:nth-child(3){width:25%;}

</style>


| PhD   | University of Tehran       | 2016 - 2024 |


<h3>
Telecommunication Engineering
</h3>

<h3>
GPA: 17.74
</h3>

<h3>Thesis:</h3>
Spatial frequency (SF) is shown to be a critical characteristic in object perception. However, there exists a lack of understanding of how the SF is represented in the brain, specifically in higher areas in the visual system hierarchy. To address this issue, we conducted extracellular recordings from macaque monkeys to investigate the representation of SF in the inferior temporal (IT) cortex. Furthermore, we investigated the impact of SF on complex object representation.

| M.Sc. | University of Tehran       | 2014 - 2016 |

<h3>
Telecommunication Engineering
</h3>

<h3>
GPA: 17.18
</h3>

<h3>Thesis: Combination of Classifiers Based on Information Theoretic Models</h3>
One of the widely used methods to construct an accurate classifier is employing an ensemble of classifiers and making a decision based on their outputs of them. The question is: “Should we use all the classifiers to make a decision?” We try to answer this question in this study. In the literature on pattern recognition, this problem is known as “classifier selection”. First, a criterion for the selection of appropriate classifiers is introduced. To introduce the criterion, an information-theoretic framework is chosen. The criterion utilizes the error distribution as well as the value of the error. In fact, employing the error distribution is the novelty of our proposed method. In addition to decreasing the value of the error, the proposed method tries to select a subset of classifiers that has an error distribution close to the desired one. Results show that there exists a trade-off between the value of the error and its distribution. That means, making the error distribution close to the desired distribution, results in the increment of the error. However, this increment is negligible, when the training dataset is small. Next, we employ this idea in steganalysis. We employ the proposed classifier selection algorithm in this problem. The proposed method has a lower error rate and a smaller number of classifiers compared to the prior works. Furthermore, the dimension of the training samples of each classifier is reduced. Finally, the proposed method is much faster in predicting the observations.

| B.Sc.   | Shahid Beheshti University | 2010 - 2014 |

<h3>
Telecommunication Engineering
</h3>

<h3>
GPA: 18.25
</h3>

<h3>Thesis: Text Detection in The Wild</h3>