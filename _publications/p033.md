---
type: 'journal'
title: "Unlocking Book Genre from Covers: A Multimodal Approach to Book Genre Prediction"
collection: publications
permalink: /publication/p033
date: 2025-07-01
venue: 'International Journal of Web Research'
paperurl: 'https://ijwr.usc.ac.ir/article_227443.html'
pdf: 'https://ijwr.usc.ac.ir/article_227443_3b524de4660f90efe5260b9465e59abf.pdf'
authors: 'Reza Toosi, Alireza Hosseini, <b>Ramin Toosi</b>, Mohammad Ali Akhaee'
---

<h3> Authors </h3>
Reza Toosi, Alireza Hosseini, <b>Ramin Toosi</b>, Mohammad Ali Akhaee

<h3> Abstract </h3>
In today's visually driven market, book cover design plays a crucial role in conveying a work's narrative and thematic essence. A book cover is a multimodal entity, consisting of various visual and textual elements. While conventional recommendation systems have often overlooked the semantic richness of cover imagery, prior work attempting to incorporate textual information relied on OCR to extract text from covers. However, these raw tokens capture only a fraction of the cover's meaning and often miss deeper thematic and narrative cues. Recognizing these limitations, we leverage the advanced knowledge accumulated in VLMs to derive a more comprehensive representation, using this knowledge to add it as an additional feature to the system. In this paper, we use VLM-generated descriptions and integrate these rich descriptions as a new textual feature. Our enhanced corpus comprises 57,000 book covers across 30 genres (1,900 per genre), each annotated with both raw imagery and VLM-generated narrative summaries. We fuse two state-of-the-art vision encoders (ViT and VisionMamba) with a text encoder that processes these VLM descriptions. Experimental results demonstrate a Top 1 accuracy of 63.31% and a Top 3 accuracy of 83.03%, marking a substantial improvement over the state-of-the-art variant and underscoring the value of VLM-derived context in multimodal genre classification.
